Use of textural measurements to map invasive wetland plants in the Hudson River National Estuarine Research Reserve with IKONOS satellite imagery
At this point, models, and accompanying field data, that could be used to predict the likely response of estuaries and tidal marshes to future environmental change are lacking. To improve this situation, monitoring efforts in these complex ecosystems need to be intensified, and new, efficient monitoring techniques should be developed. In this context, our research assessed the use of IKONOS satellite imagery to map plant communities at Tivoli Bays, in the Hudson River National Estuarine Research Reserve (HRNERR). Tivoli Bays, a freshwater tidal wetland, contains a unique assemblage of plant communities, including three invasive plants (Trapa natans, Phragmites australis, and Lythrum salicaria). To study the effects of textural information on the accuracy of land cover maps produced for the HRNERR, seven different 11-class land cover maps were produced using a maximum-likelihood classification on seven combinations of spectral and textural data derived from an IKONOS image. Conventional contingency tables served as a basis for an accuracy assessment of these maps. The overall classification accuracies, as assessed by the contingency tables, ranged from 45% to 77.7%. The maximum-likelihood classification relying on four spectral and four 5-by-5 filter textural bands (created by superposing a textural filter separately on each band of the IKONOS image) had the lowest overall accuracy, whereas the one based on four spectral and four 3-by-3 filter textural bands associated with all segments, identified by an object-based classification of the IKONOS image, had the highest accuracy. Results suggest that a combination of per-pixel classification and incorporation of texture for segments generated through an object-based classification slightly increases classification accuracy from 76.2% for the maximum-likelihood classification of the four spectral bands of the IKONOS image to 77.7% for the combination of spectral and textural information produced for selected segments. Further analysis indicates that better results may be obtained by using other types of data within the segments and that the traditional approach to the selection of training and accuracy sites may negatively bias the results for a combination per-pixel and object-based classification.
10.1016/J.RSE.2009.12.002